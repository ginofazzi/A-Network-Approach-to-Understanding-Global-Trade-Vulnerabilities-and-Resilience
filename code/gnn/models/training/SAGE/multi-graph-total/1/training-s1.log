epoch,train_loss,val_loss
1,0.0903,0.0793
2,0.0819,0.0786
3,0.0821,0.0785
4,0.0832,0.0785
5,0.0829,0.0785
6,0.0810,0.0785
7,0.0824,0.0785
8,0.0820,0.0785
9,0.0814,0.0785
10,0.0825,0.0785
11,0.0812,0.0785
12,0.0845,0.0785
13,0.0833,0.0785
14,0.0821,0.0785
15,0.0814,0.0785
16,0.0835,0.0785
17,0.0794,0.0785
18,0.0818,0.0785
19,0.0839,0.0785
20,0.0829,0.0785
21,0.0834,0.0785
22,0.0818,0.0785
23,0.0827,0.0785
24,0.0810,0.0785
25,0.0801,0.0785
26,0.0836,0.0785
27,0.0833,0.0785
28,0.0825,0.0785
29,0.0821,0.0785
30,0.0805,0.0785
31,0.0798,0.0785
32,0.0827,0.0785
33,0.0830,0.0785
34,0.0825,0.0785
35,0.0835,0.0785
36,0.0830,0.0785
37,0.0811,0.0785
38,0.0825,0.0785
39,0.0816,0.0785
40,0.0816,0.0785
41,0.0810,0.0785
42,0.0812,0.0785
43,0.0825,0.0785
44,0.0823,0.0785
45,0.0846,0.0785
46,0.0822,0.0785
47,0.0814,0.0785
48,0.0813,0.0785
49,0.0828,0.0785
50,0.0822,0.0785
51,0.0820,0.0785
52,0.0822,0.0785
53,0.0837,0.0785
54,0.0816,0.0785
55,0.0834,0.0785
56,0.0832,0.0785
57,0.0822,0.0785
58,0.0841,0.0785
59,0.0818,0.0785
